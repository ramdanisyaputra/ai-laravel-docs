# ğŸš€ Advanced Laravel Documentation RAG System

An intelligent Laravel documentation assistant that uses **dynamic LLM tool selection** with Retrieval-Augmented Generation (RAG) for accurate, context-aware responses about Laravel framework.

## ğŸŒŸ Features

- **ğŸ§  Intelligent Tool Selection**: GPT-4.1 orchestrator automatically chooses the best tools for each question
- **ğŸ’° Cost-Optimized Architecture**: Strategic use of GPT-4.1 for orchestration and GPT-3.5-turbo for specialized tasks
- **ğŸ”„ Dynamic RAG**: Retrieval-Augmented Generation with specialized tools for different query types
- **ğŸ“š Laravel 12.x Documentation**: Complete Laravel documentation crawled and vectorized using Firecrawl
- **ğŸ” Multi-Query Search**: Advanced search strategies with FAISS vector similarity search
- **ğŸ’¬ One Interfaces**: Command-line, and interactive chat
- **ğŸ“Š Vector Store Management**: Persistent FAISS storage with automatic loading/creation

## ğŸ—ï¸ System Architecture

2. **ğŸ”§ Specialized Tools**: Execute specific tasks using optimized models for each domain
3. **ğŸ¨ Final Answerer (GPT-3.5-turbo)**: Synthesizes tool results into comprehensive responses

### Cost-Optimized Model Strategy

**ğŸ§  Intelligent Tool Selection**: GPT-4.1 orchestrator automatically chooses the best tools for each question
**ğŸ’° Cost-Optimized Architecture**: Strategic use of GPT-4.1 for orchestration and GPT-3.5-turbo for specialized tasks
**Final Answerer** | GPT-3.5-turbo | Response synthesis and formatting | Optimized |

## ğŸ“ Project Structure

```
laravel-docs/
â”œâ”€â”€ main.py                     # ğŸ¯ Command-line interface
â”œâ”€â”€ run_app.sh                  # ğŸš€ Shell script launcher
â”œâ”€â”€ chat/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dynamic_rag_system.py   # ğŸ§  Core RAG system with dynamic tool selection
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vector_store.py         # ğŸ“Š FAISS vector store management
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ tools.py                # ğŸ” Firecrawl Laravel documentation scraper
â”œâ”€â”€ laravel_faiss_index/        # ğŸ’¾ Persistent vector store storage
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”œâ”€â”€ requirements.txt            # ğŸ“¦ Python dependencies (pip)
â”œâ”€â”€ Pipfile                     # ğŸ“¦ Python dependencies (pipenv)
â”œâ”€â”€ Pipfile.lock               # ğŸ”’ Locked dependency versions
â””â”€â”€ README.md                   # ğŸ“– This documentation
```

## ğŸ”„ How It Works

### 1. System Initialization

```python
# Automatic vector store management
vector_store = LaravelDocsVectorStore()
try:
    vector_store.load_local()  # Load existing FAISS index
except:
    # Create new vector store from Laravel docs
    docs = get_laravel_docs()  # Firecrawl scraping
    vector_store.create_vector_store(docs)
    vector_store.save_local()

# Initialize advanced RAG system
chatbot = AdvancedRAGWithDynamicTools(vector_store)
```

### 2. Intelligent Query Processing

```python
def chat(self, question: str) -> str:
    # Step 1: ğŸ§  GPT-4 Orchestrator Analysis
    orchestrator_response = self.orchestrator_llm.invoke({
        "question": question
    })
    
    # Step 2: ğŸ”§ Dynamic Tool Selection & Execution
    tool_plan = json.loads(orchestrator_response)
    tool_results = []
    
    for tool_info in tool_plan["tools"]:
        tool_name = tool_info["name"]
        tool_query = tool_info["query"]
        
        # Execute selected tool with optimized model
        tool = self.find_tool(tool_name)
        result = tool.func(tool_query)
        tool_results.append(result)
    
    # Step 3: ğŸ¨ Final Response Synthesis (GPT-3.5-turbo)
    final_response = self.final_llm.invoke({
        "question": question,
        "tool_results": combined_results
    })
    
    return final_response
```

### 3. Specialized Tool Execution

Each tool follows this optimized pattern:

```python
def specialized_tool(query: str) -> str:
    # 1. ğŸ” Multi-Query Vector Search
    searches = generate_search_variations(query)
    
    # 2. ğŸ“Š FAISS Similarity Search
    relevant_docs = []
    for search in searches:
        docs = vector_store.similarity_search(search, k=3)
        relevant_docs.extend(docs)
    
    # 3. ğŸ§¹ Deduplication & Context Formation
    unique_docs = remove_duplicates(relevant_docs)
    context = format_context(unique_docs)
    
    # 4. ğŸ¤– Model-Optimized Processing
    llm = ChatOpenAI(model=get_optimal_model(query_type))
    result = llm.invoke({"query": query, "context": context})
    
    return result
```

## ğŸ› ï¸ Available Specialized Tools

### 1. **ğŸ” Version Search Tool**
- **Model**: GPT-3.5-turbo (cost-effective for simple extraction)
- **Purpose**: Extract Laravel version information and release details
- **Search Patterns**: Version numbers, release notes, upgrade guides, changelog
- **Example**: *"What's the current Laravel version?"*

### 2. **âš™ï¸ Feature Search Tool** 
- **Model**: GPT-4 (high-quality for complex explanations)
- **Purpose**: Detailed feature explanations with practical code examples
- **Search Patterns**: Middleware, routing, Eloquent, validation, authentication, events
- **Example**: *"How does Laravel middleware work with code examples?"*

### 3. **ğŸ“¦ Installation Search Tool**
- **Model**: GPT-3.5-turbo (structured guidance)
- **Purpose**: Step-by-step installation and setup instructions
- **Search Patterns**: Requirements, installation steps, environment setup, getting started
- **Example**: *"How do I install Laravel with Composer?"*

### 4. **ğŸ“š General Search Tool**
- **Model**: GPT-3.5-turbo (versatile and economical)
- **Purpose**: General Laravel documentation queries and best practices
- **Search Patterns**: Any Laravel-related topics, best practices, troubleshooting
- **Example**: *"Laravel testing best practices"*

## ğŸš€ Getting Started

### Prerequisites

```bash
# Python 3.8+ required
python --version

# Install dependencies (choose one method)

# Method 1: Using pip
pip install -r requirements.txt

# Method 2: Using pipenv (recommended)
pipenv install
```

### Environment Setup

Create a `.env` file or set environment variables:

```bash
# Required: OpenAI API key for GPT models
export OPENAI_API_KEY="your-openai-api-key-here"

# Required: Firecrawl API key for documentation scraping
export FIRECRAWL_API_KEY="your-firecrawl-api-key-here"
```

### Quick Start Options

#### Option 1: Command Line Interface (Recommended)
```bash
# Using pipenv
pipenv run python main.py

# Or using pip
python main.py
```

#### Option 2: Web Interface
```bash
# Using pipenv
pipenv run python app.py

# Or using pip
python app.py
```

#### Option 3: Shell Script Launcher
```bash
# Automated setup with virtual environment
chmod +x run_app.sh
./run_app.sh
```

### First Run

On first launch, the system will:
1. **ğŸ” Check for existing vector store** - Looks for `laravel_faiss_index/`
2. **ğŸ“¥ Download Laravel docs** - Uses Firecrawl to scrape Laravel 12.x documentation 
3. **ğŸ”® Create vector embeddings** - Processes ~1,500+ documentation chunks
4. **ğŸ’¾ Save vector store** - Persists FAISS index for future use
5. **âœ… Ready to chat!** - Interactive assistant is ready

## ğŸ’¬ Usage Examples

### Command Line Chat
```
ğŸš€ Advanced Laravel Documentation RAG System
============================================================
âœ… Vector store loaded successfully!
âœ… Advanced RAG with Dynamic Tools initialized!

ğŸ¤– Advanced Laravel Bot: Hello! I'm your advanced Laravel documentation assistant.
I use intelligent tool selection where the LLM DECIDES which tools to use!

ğŸ‘¤ You: What's new in Laravel 12?

ğŸ§  Step 1: Orchestrator analyzing question...
ğŸ¤– Orchestrator selects: ["version_search"] 
ğŸ”§ Step 2: Executing version_search tool...
ğŸ¨ Step 3: Synthesizing final response...

ğŸ¤– Laravel Bot: Laravel 12.x introduces several exciting features:

1. **Enhanced Performance**: Improved query optimization...
2. **New Artisan Commands**: Additional CLI tools for...
3. **Security Updates**: Enhanced middleware protection...
```

### Web Interface Features
-- **ğŸ–¥ï¸ User-friendly GUI**: Clean web interface
- **âš¡ Real-time responses**: Streaming conversation display
- **ğŸ”„ Auto-initialization**: Automatic system setup on first load
- **ğŸ“± Responsive design**: Works on desktop and mobile

### Available Chat Commands
```
help        - Show available commands and usage
tools       - Display all specialized tools and their purposes
history     - Show conversation history
clear       - Clear chat history and start fresh
quit/exit   - Exit the application
```

## ğŸ¯ Example Interactions

### Version Information Query
```
ğŸ‘¤ You: What version of Laravel is currently available?

ï¿½ Laravel Bot: The current version is Laravel 12.x. This latest release includes:

â€¢ **Performance Improvements**: Enhanced query builder optimization
â€¢ **New Features**: Advanced middleware capabilities, improved validation
â€¢ **Developer Experience**: Better error messages and debugging tools
â€¢ **Security**: Updated security patches and vulnerability fixes

To upgrade from Laravel 11.x, you can follow the upgrade guide...
```

### Feature Deep-Dive Query
```
ğŸ‘¤ You: How does Laravel middleware work? Show me examples.

ğŸ¤– Laravel Bot: Laravel middleware acts as a filter for HTTP requests entering your application. Here's a comprehensive guide:

## Creating Middleware
```php
// Generate middleware
php artisan make:middleware CheckAge

// app/Http/Middleware/CheckAge.php
<?php
namespace App\Http\Middleware;
use Closure;

class CheckAge
{
    public function handle($request, Closure $next)
    {
        if ($request->age <= 18) {
            return redirect('home');
        }
        return $next($request);
    }
}
```

## Registering Middleware
```php
// app/Http/Kernel.php
protected $routeMiddleware = [
    'age' => \App\Http\Middleware\CheckAge::class,
];
```

## Using Middleware
```php
// In routes
Route::get('admin/profile', function () {
    //
})->middleware('age');
```
```

### Installation Guidance Query
```
ğŸ‘¤ You: How do I install Laravel from scratch?

ğŸ¤– Laravel Bot: Here's a step-by-step guide to install Laravel:

## Prerequisites
- PHP >= 8.2
- Composer (dependency manager)
- Node.js & npm (for frontend assets)

## Installation Methods

### Method 1: Laravel Installer (Recommended)
```bash
# Install Laravel installer globally
composer global require laravel/installer

# Create new Laravel project
laravel new my-project

# Navigate to project
cd my-project
```

### Method 2: Composer Create-Project
```bash
composer create-project laravel/laravel my-project
cd my-project
```

## Post-Installation Setup
```bash
# Copy environment file
cp .env.example .env

# Generate application key
php artisan key:generate

# Start development server
php artisan serve
```

Your Laravel application will be available at `http://localhost:8000`
```

## ğŸ“Š Performance & Optimization

### Cost-Effective Model Usage
- **~70% Cost Reduction**: Strategic model selection vs. using GPT-4.1 for everything
- **Smart Orchestration**: GPT-4.1 used only for complex decision-making
- **Bulk Processing**: GPT-3.5-turbo handles most content processing efficiently

### Vector Store Performance
- **âš¡ FAISS Speed**: Millisecond similarity search across 1,500+ documentation chunks
- **ğŸ—œï¸ Optimized Chunks**: 1000-character chunks with 200-character overlap for context
- **ğŸ”„ Smart Caching**: Persistent storage eliminates re-processing on restart
- **ğŸ§¹ Deduplication**: Automatic removal of duplicate content from search results

### Query Optimization
- **ğŸ¯ Multi-Query Strategy**: Multiple search variations for comprehensive results
- **ğŸ” Relevance Scoring**: FAISS similarity scores for best context selection
- **âš–ï¸ Context Balancing**: Optimal context window usage without token waste

## ğŸ”§ Advanced Configuration

### Environment Variables
```bash
# Core API Keys
OPENAI_API_KEY="sk-..."              # Required for all LLM operations
FIRECRAWL_API_KEY="fc-..."           # Required for documentation scraping

# Optional Customizations
VECTOR_STORE_PATH="custom_index"     # Default: laravel_faiss_index
CHUNK_SIZE="1000"                    # Default: 1000 characters
CHUNK_OVERLAP="200"                  # Default: 200 characters
EMBEDDING_MODEL="text-embedding-3-small"  # Default model for embeddings
```

### System Customization
```python
# Custom vector store configuration
vector_store = LaravelDocsVectorStore(
    model_name="text-embedding-3-large",  # Higher quality embeddings
    chunk_size=1500,                      # Larger chunks for more context
    chunk_overlap=300                     # More overlap for better continuity
)

# Custom LLM configuration
chatbot = AdvancedRAGWithDynamicTools(
    vector_store,
    temperature=0.0,                      # More deterministic responses
    orchestrator_model="gpt-4.1-turbo"      # Latest GPT-4.1 variant
)
```

## ğŸ› Troubleshooting

### Common Issues

#### Vector Store Creation Fails
```bash
# Issue: FAISS installation problems
pip install faiss-cpu --no-cache-dir

# Issue: Insufficient memory
# Reduce chunk size in vector_store.py
chunk_size=500, chunk_overlap=50
```

#### API Key Errors
```bash
# Verify API keys are set
echo $OPENAI_API_KEY
echo $FIRECRAWL_API_KEY

# Test API connectivity
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models
```

#### Documentation Scraping Issues
```bash
# Clear existing vector store and rebuild
rm -rf laravel_faiss_index/
python main.py  # Will automatically rebuild
```

### Error Handling Features
- **ğŸ”„ Automatic Fallback**: Falls back to general search if specialized tools fail
- **ğŸ›¡ï¸ Graceful Degradation**: System continues working even if some tools are unavailable
- **ğŸ“ Detailed Logging**: Comprehensive error messages for debugging
- **âš¡ Recovery Mechanisms**: Automatic retry logic for transient failures

## ï¿½ Advanced Features

### Dynamic Tool Selection Logic
The GPT-4.1 orchestrator uses sophisticated prompts to analyze queries:

```
Query Type Analysis:
- Version/Release â†’ version_search_tool
- Code Examples/Features â†’ feature_search_tool  
- Installation/Setup â†’ installation_search_tool
- General Questions â†’ general_search_tool
- Complex Multi-part â†’ multiple tools
```

### Multi-Tool Orchestration
```python
# Example: Complex query using multiple tools
query = "How do I install Laravel and set up middleware?"

orchestrator_response = {
    "tools": [
        {"name": "installation_search", "query": "install Laravel setup"},
        {"name": "feature_search", "query": "middleware setup examples"}
    ]
}
```

### Chat Memory Management
- **ğŸ’­ Conversation Context**: Maintains conversation history for context-aware responses
- **ğŸ§¹ Smart Cleanup**: Automatic history management to prevent token overflow
- **ğŸ“Š History Analysis**: Uses conversation context to improve subsequent responses

### Error Recovery & Fallbacks
```python
try:
    # Attempt specialized tool execution
    result = specialized_tool.func(query)
except Exception as e:
    # Fallback to general search
    result = general_search_tool.func(query)
    logger.warning(f"Fallback used for query: {query}")
```

## ğŸ§© Core Components

### `main.py` - Command Line Interface
```python
# Main orchestration and user interaction
- Automatic vector store management
- Interactive chat loop with command support  
- Error handling and graceful degradation
- Real-time system status feedback
```

### `app.py` - Web Interface
```python
# Modern web-based interface
# Progressive initialization with live updates
# State management across sessions
# Automatic system setup workflow
```

### `chat/dynamic_rag_system.py` - Core RAG Engine
```python
# Advanced RAG implementation
- AdvancedRAGWithDynamicTools: Main orchestrator class
- DynamicLLMTool: Individual tool wrapper with model optimization
- Multi-stage prompt engineering for tool selection
- Conversation history management with memory
```

### `embeddings/vector_store.py` - Vector Management
```python  
# FAISS-powered vector operations
- LaravelDocsVectorStore: Complete vector store lifecycle
- Embedding creation with OpenAI text-embedding-3-small
- Persistent storage and loading capabilities
- Similarity search with configurable parameters
```

### `tools/tools.py` - Documentation Scraper
```python
# Firecrawl-based content extraction
- get_laravel_docs(): Complete Laravel 12.x documentation scraping
- Rate limiting and error handling for web scraping
- Comprehensive URL coverage (60+ documentation pages)
- Content cleaning and preprocessing
```

## ğŸ—ï¸ Technical Architecture

### Dependencies

#### Core LangChain Stack
```python
langchain>=0.1.0                 # Core framework
langchain-openai>=0.0.2          # OpenAI integration  
langchain-community>=0.0.10      # FAISS and utilities
langchain-core>=0.1.0            # Base abstractions
```

#### Vector & ML Libraries
```python
faiss-cpu>=1.7.4                 # Vector similarity search
openai>=1.0.0                    # Direct API access
tiktoken>=0.5.0                  # Token counting utilities
numpy>=1.24.0                    # Numerical computations
```

#### Web & Interface
```python
firecrawl-py>=0.0.8             # Web scraping service
```

#### Utilities
```python
python-dotenv>=1.0.0            # Environment variable management
```

### Data Flow Architecture

```
ğŸ“„ Laravel Docs (Web) 
    â†“ [Firecrawl API]
ğŸ“¦ Raw Text Content
    â†“ [Text Splitter]  
ğŸ§© Document Chunks (1000 chars + 200 overlap)
    â†“ [OpenAI Embeddings]
ğŸ”¢ Vector Embeddings (1536 dimensions)
    â†“ [FAISS Index]
ğŸ’¾ Persistent Vector Store
    â†“ [Similarity Search]
ğŸ“‹ Relevant Context
    â†“ [LLM Tools]
ğŸ¤– AI Response
```

### Memory Management

```python
# Conversation History Storage
class ChatMessageHistory:
    - Human messages: User queries and commands
    - AI messages: Bot responses and tool outputs
    - System messages: Tool selection decisions
    - Automatic pruning: Prevents token overflow
```

### Tool Selection Logic

```python
# GPT-4.1 Orchestrator Decision Tree
def select_tools(query: str) -> List[str]:
    """
    Intelligent tool selection based on query analysis:
    
    - Keywords: "version", "release" â†’ version_search
    - Keywords: "install", "setup" â†’ installation_search  
    - Keywords: "how to", "example" â†’ feature_search
    - General queries â†’ general_search
    - Complex queries â†’ multiple tools
    """
```

## ğŸ“ˆ Monitoring & Analytics

### Performance Metrics
- **ğŸ• Response Time**: Average 2-5 seconds for complex queries
- **ğŸ’° Cost Per Query**: ~$0.02-0.05 depending on complexity and tools used  
- **ğŸ¯ Accuracy Rate**: High accuracy due to specialized tool selection
- **ğŸ“Š Token Usage**: Optimized context windows prevent waste

### Usage Statistics
```python
# Trackable Metrics
- Total queries processed
- Tool selection frequency  
- Error rates by tool type
```

## ğŸš€ Future Enhancements

### Planned Features
- [ ] **ğŸ” Enhanced Tool Arsenal**: Debug tools, testing assistants, deployment guides
- [ ] **âš¡ Intelligent Caching**: Cache frequent queries to reduce API costs and improve response times  
- [ ] **ğŸ“š Multi-Framework Support**: Extend to Symfony, CodeIgniter, other PHP frameworks
- [ ] **ğŸ”— Official API Integration**: Direct Laravel.com documentation API integration
- [ ] **ğŸ§  Advanced Memory**: Long-term conversation context and user preference learning
- [ ] **ğŸ“Š Analytics Dashboard**: Usage statistics, popular queries, performance metrics
- [ ] **ğŸŒ Multi-Language Support**: Documentation in multiple languages
- [ ] **ğŸ”§ Custom Tool Builder**: Allow users to create domain-specific tools

### Contributing Opportunities

#### ğŸ› ï¸ Tool Development
```python
# Example: Add new debugging tool
class DebuggingTool(DynamicLLMTool):
    def __init__(self, vector_store_manager):
        super().__init__(
            name="debugging_search",
            description="Laravel debugging and troubleshooting",
            func=self.debug_search,
            vector_store_manager=vector_store_manager,
            model_name="gpt-4.1"  # Complex debugging needs GPT-4.1
        )
```

#### ğŸ“ˆ Performance Improvements
- Implement embedding caching for frequently accessed content
- Add semantic caching for similar queries
- Optimize vector store chunk sizes for different content types
- Implement parallel tool execution for independent operations

### How to Contribute
1. **ğŸ´ Fork the Repository**
   ```bash
   git clone https://github.com/ramdanisyaputra/ai-laravel-docs.git
   cd ai-laravel-docs
   ```

2. **ğŸ”§ Set Up Development Environment**
   ```bash
   # Create virtual environment
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # or
   venv\Scripts\activate  # Windows
   
   # Install dependencies
   pip install -r requirements.txt
   ```

3. **ğŸ§ª Test Your Changes**
   ```bash
   # Run existing functionality
   python main.py

4. **ğŸ“ Submit Pull Request**
   - Ensure code follows existing patterns
   - Add comprehensive documentation
   - Include example usage in README updates
   - Test with different query types

## ğŸ“ Support & Community

### Getting Help
- **ğŸ› Bug Reports**: Open GitHub issues with detailed reproduction steps
- **ğŸ’¡ Feature Requests**: Describe use cases and expected behavior  
- **â“ Questions**: Use GitHub Discussions for general questions
- **ğŸ“§ Direct Contact**: For sensitive issues or collaboration inquiries

### Best Practices for Issues

#### Bug Reports Template
```markdown
## Bug Description
Brief description of the issue

## Steps to Reproduce
1. Step one
2. Step two  
3. Step three

## Expected Behavior
What should happen

## Actual Behavior
What actually happens

## Environment
- Python version:
- OS:
- API key status: (set/not set, don't share actual keys)
```

## ğŸ“„ License & Legal

### MIT License
```
MIT License

Copyright (c) 2024 Laravel Documentation RAG System

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

### Third-Party Services
- **OpenAI API**: Subject to OpenAI's usage policies and pricing
- **Firecrawl API**: Subject to Firecrawl's terms of service
- **Laravel Documentation**: Respects Laravel's documentation licensing

### Data & Privacy
- **ğŸ”’ No User Data Storage**: Conversations not permanently stored
- **ğŸ”‘ API Key Security**: Keys processed locally, not transmitted to third parties
- **ğŸ“Š Anonymous Usage**: No personal information collected or tracked

---

## ğŸ‰ Acknowledgments

**Built with â¤ï¸ using:**
- **ğŸ¦œ LangChain**: Comprehensive LLM framework and orchestration
- **ğŸ¤– OpenAI**: GPT-4.1 and GPT-3.5-turbo models for intelligent responses  
- **âš¡ FAISS**: Facebook's efficient similarity search and clustering
- **ğŸ”¥ Firecrawl**: Reliable web scraping and content extraction
- **ğŸ Python**: The foundation that makes it all possible

**Special thanks to:**
- Laravel team for comprehensive documentation
- LangChain community for excellent tools and examples
- OpenAI for powerful and accessible language models
- Contributors and users who make this project better

---

<div align="center">

### ğŸŒŸ Star this repository if you find it useful! 

#### Ready to get started? [Jump to Getting Started](#-getting-started)

**Happy coding with Laravel! ğŸš€**

</div>
# ai-laravel-docs
